{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f4d0b1",
   "metadata": {},
   "source": [
    "##### Author: Jimin Kim (jk55@uw.edu)\n",
    "##### Version 1.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dd830",
   "metadata": {},
   "source": [
    "# Lab 4 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b76e12f",
   "metadata": {},
   "source": [
    "## Group Members: Tuan Huynh, Caitlin DeShazo-Couchot\n",
    "## Group Name for Leaderboard: Caitie and Tuan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d45e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900d0d0",
   "metadata": {},
   "source": [
    "### Exercise 1: Construct Dictionaries from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87db7d24",
   "metadata": {},
   "source": [
    "<img src=\"lab4_exercise1.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f1a2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib  # Use pathlib to work with paths\n",
    "def convert_csv_to_dict(file_path):\n",
    "    # Create an object of file path\n",
    "    a_path=pathlib.Path(file_path)\n",
    "    # Extract file name from file path\n",
    "    file_name=a_path.name\n",
    "    # Load csv file using read_csv()\n",
    "    csv_object = pd.read_csv(file_name)\n",
    "    # Create a dictionary object\n",
    "    dict_object={}\n",
    "    # Set the first key and its value for the dictionary\n",
    "    dict_object[\"Filename\"] = file_name\n",
    "    # Convert csv file to Numpy array with .to_numpy() \n",
    "    csv_object_np = csv_object.to_numpy()\n",
    "    # create a variable for the order of the csv object column \n",
    "    i=0\n",
    "    # Implement for loop, traverse all the attributes of csv object\n",
    "    # The attributes of csv object is the key of the dictionary object\n",
    "    for name in csv_object.columns:\n",
    "        # Set the value for each key of the dictionary object\n",
    "        # The value of each key is a numpy array taking the values in all the rows of i_th column of csv object \n",
    "        dict_object[name] = np.array(csv_object_np[:, i])\n",
    "        # Increase the order of column by 1\n",
    "        i=i+1\n",
    "    \n",
    "    return dict_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b92b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSLA_dict = convert_csv_to_dict('your file path to TSLA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7b05fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to keys corresponding to 2nd and 4th columns (Open and Low prices) of TSLA.csv, \n",
    "# Print first 10 elements of each key.\n",
    "\n",
    "TSLA_column2 = \"Open\"\n",
    "TSLA_column4 = \"Low\"\n",
    "print(TSLA_dict[TSLA_column2][:10])\n",
    "print(TSLA_dict[TSLA_column4][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e943cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_dict = convert_csv_to_dict('your file path to diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad77d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to keys corresponding to 2nd and 4th columns (Glucose and SkinThickness) of diabetes.csv, \n",
    "# Print first 10 elements of each key.\n",
    "\n",
    "diabetes_column2 = \"Glucose\"\n",
    "diabetes_column4 = \"SkinThickness\"\n",
    "print(diabetes_dict[diabetes_column2][:10])\n",
    "print(diabetes_dict[diabetes_column4][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0da37",
   "metadata": {},
   "source": [
    "### Exercise 2: Bar graph with confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dd5f4",
   "metadata": {},
   "source": [
    "<img src=\"lab4_exercise2.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfda82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes.csv \n",
    "import scipy.stats as st                # Import scipy.stats to use pre-built statstical functions\n",
    "\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "# Convert to Numpy array with .to_numpy() \n",
    "diabetes_np = diabetes.to_numpy() \n",
    "# Extract rows index with diabetes and no diabetes using Boolean masks\n",
    "diabetes_pos_ind = diabetes_np[:, -1] == 1  \n",
    "diabetes_neg_ind = diabetes_np[:, -1] == 0 \n",
    "# Split dataset into two subsets of diabetic and non-diabetic\n",
    "diabetes_np_pos = diabetes_np[diabetes_pos_ind, :]  \n",
    "diabetes_np_neg = diabetes_np[diabetes_neg_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0873e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract glucose, blood pressure, and BMI metrics from diabetic and non-diabetic\n",
    "\n",
    "# Extract glucose from non-diabetic metrics\n",
    "non_diabetic_glucose = diabetes_np_neg[:,1]\n",
    "# Extract blood pressure from non-diabetic metrics\n",
    "non_diabetic_bp = diabetes_np_neg[:,2]\n",
    "# Extract BMI from non-diabetic metrics\n",
    "non_diabetic_bmi = diabetes_np_neg[:,5]\n",
    "\n",
    "# Extract glucose from diabetic metrics\n",
    "diabetic_glucose =  diabetes_np_pos[:,1]\n",
    "# Extract blood pressure from diabetic metrics\n",
    "diabetic_bp = diabetes_np_pos[:,2]\n",
    "# Extract BMI from non-diabetic metrics\n",
    "diabetic_bmi = diabetes_np_pos[:,5]\n",
    "# Create a list of three 1D arrays each corresponding to glucose, blood pressure, and BMI \n",
    "non_diabetic_list = [non_diabetic_glucose, non_diabetic_bp, non_diabetic_bmi]\n",
    "diabetic_list = [diabetic_glucose, diabetic_bp, diabetic_bmi]\n",
    "# Create a list of three bar labels \n",
    "non_diabetic_bar_labels = ['non_diabetic_glucose', 'non_diabetic_bp', 'non_diabetic_bmi']\n",
    "diabetic_bar_labels = ['diabetic_glucose', 'diabetic_bp', 'diabetic_bmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e87c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_bargraph_CI(data_vec_list, conf_level, bar_labels):\n",
    "    # Find the length of the data list\n",
    "    x = len(data_vec_list)\n",
    "    # Create original arrays with the size x to do for loop\n",
    "    CI_lower = np.zeros(x)\n",
    "    CI_upper = np.zeros(x)\n",
    "    h = np.zeros(x)\n",
    "    # Implement for loop, find the lower and upper bound for provided confidence level\n",
    "    for i in range(0,x):\n",
    "        CI_lower[i], CI_upper[i] = st.t.interval(alpha=conf_level, df=len(data_vec_list[i])-1, \n",
    "                                      loc=np.mean(data_vec_list[i]), scale=st.sem(data_vec_list[i]))\n",
    "        # st.t.interval() computes lower and upper bound for provided confidence level\n",
    "        # alpha - confidence level\n",
    "        # df - degree of freedom (size of the data - 1)\n",
    "        # loc - The mean value of the data\n",
    "        # scale = standard error of the data\n",
    "        h[i] = CI_upper[i] - np.mean(data_vec_list[i])        # Confidence interval size\n",
    "        plt.bar([bar_labels[i]], [np.mean(data_vec_list[i])], # Define x and y-axis data for the bar\n",
    "        width = 0.4, color = 'black',                         # Define visual property of the main bar\n",
    "        yerr = [h[i]], ecolor = 'grey',                       # Define the confidence interval size and error bar color\n",
    "        error_kw=dict(lw=5, capsize=30, capthick=1))          # Define visual properties of the confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccb2595",
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_bargraph_CI(data_vec_list = non_diabetic_list, conf_level = 0.99, bar_labels = non_diabetic_bar_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4452891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_bargraph_CI(data_vec_list = diabetic_list, conf_level = 0.95, bar_labels = diabetic_bar_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bb0604",
   "metadata": {},
   "source": [
    "### Exercise 3: Rolling Mean/Median Function from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0620a",
   "metadata": {},
   "source": [
    "<img src=\"lab4_exercise3.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b82271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stock datasets\n",
    "\n",
    "tesla = pd.read_csv('TSLA.csv') \n",
    "tesla_np = tesla.to_numpy()\n",
    "\n",
    "google = pd.read_csv('GOOGL.csv') \n",
    "google_np = google.to_numpy()\n",
    "\n",
    "dji = pd.read_csv('DJI.csv') \n",
    "dji_np = dji.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6146a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract closing price for each stock data\n",
    "\n",
    "tesla_np_closing = tesla_np[:, 4]\n",
    "google_np_closing = google_np[:, 4]\n",
    "DJI_np_closing = dji_np[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da865892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_data(data_arr, smooth_type, window_size):\n",
    "    # Find the length of the data array\n",
    "    x= len(data_arr)\n",
    "    # Set the length of the smoothed data array, rolling operation reduces the data length by (window size - 1)\n",
    "    smoothed_data_arr = np.zeros(x-(window_size-1))\n",
    "    # Implement for loop x-(window_size-1) times\n",
    "    for i in range(x-(window_size-1)):\n",
    "         # Implement conditional statements for 2 cases of smoothing\n",
    "        if smooth_type=='mean':\n",
    "            smoothed_data_arr[i] = np.ceil(np.mean(data_arr[i:window_size-1+i]))\n",
    "        else: #smooth_type == 'median'\n",
    "            smoothed_data_arr[i] = np.median(data_arr[i:window_size-1+i]) \n",
    "    # Return smoothed data array\n",
    "    return smoothed_data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tesla closing prices, smooth_type = 'mean', window_size = 100\n",
    "# Note your smoothed data will be shorter than the original\n",
    "\n",
    "smoothed_tsla_closing  = smooth_data(tesla_np_closing, smooth_type = 'mean', window_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot smoothed_tsla_closing on top of tesla_np_closing\n",
    "plt.subplot(311)\n",
    "# Plot smoothed tesla closing prices with linestyle='dashed'\n",
    "plt.plot(smoothed_tsla_closing, linewidth = 2, color = 'red',linestyle='dashed' ) \n",
    "# Plot original tesla closing prices with linestyle='solid'\n",
    "plt.plot(tesla_np_closing, linewidth = 2, color = 'black',linestyle='solid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29535d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google closing prices, smooth_type = 'median', window_size = 150\n",
    "# Note your smoothed data will be shorter than the original\n",
    "\n",
    "smoothed_google_closing  = smooth_data(google_np_closing, smooth_type = 'median', window_size = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d4ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot smoothed_google_closing on top of google_np_closing\n",
    "\n",
    "plt.subplot(312)\n",
    "# Plot smoothed google closing prices with linestyle='dashed'\n",
    "plt.plot(smoothed_google_closing, linewidth = 2, color = 'red', linestyle='dashed') \n",
    "# Plot original google closing prices with linestyle='solid'\n",
    "plt.plot(google_np_closing, linewidth = 2, color = 'black', linestyle='solid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dow Jones Index closing prices, smooth_type = 'mean', window_size = 200\n",
    "# Note your smoothed data will be shorter than the original\n",
    "\n",
    "smoothed_dji_closing  = smooth_data(DJI_np_closing, smooth_type = 'mean', window_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb96963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot smoothed_dji_closing on top of dji_np_closing\n",
    "\n",
    "plt.subplot(313)\n",
    "# Plot smoothed DJI closing prices with linestyle='dashed'\n",
    "plt.plot(smoothed_dji_closing, linewidth = 1, color = 'red', linestyle='dashed' ) \n",
    "# Plot original DJI closing prices with linestyle='solid'\n",
    "plt.plot(DJI_np_closing, linewidth = 1, color = 'black', linestyle='solid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5e941",
   "metadata": {},
   "source": [
    "## Extra credit: Code efficiency\n",
    "### Achieve a runtime speed of < 50ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit -n 1 -r 7 smoothed_google_closing  = smooth_data(google_np_closing, smooth_type = 'median', window_size = 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1317ff",
   "metadata": {},
   "source": [
    "### Exercise 4: Ranking Daily Stock Surges/Crashes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744515b",
   "metadata": {},
   "source": [
    "<img src=\"lab4_exercise4.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e42ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_surge_crash(filepath, detect_type, num_output_dates):\n",
    "    \n",
    "    # Create an object of file path\n",
    "    a_path=pathlib.Path(filepath)\n",
    "    # Extract file name from file path\n",
    "    filename=a_path.name\n",
    "    # Load csv file using read_csv()\n",
    "    csv_object = pd.read_csv(filename)\n",
    "    # Convert csv file to Numpy array with .to_numpy() \n",
    "    csv_object_np = csv_object.to_numpy()\n",
    "    # Extract close data, open data and dates from csv_object\n",
    "    close_data=csv_object_np[:,4]\n",
    "    open_data=csv_object_np[:,1]\n",
    "    date_data=csv_object_np[:,0]\n",
    "    # Find the length of data array\n",
    "    x=len(close_data)\n",
    "    # Create an original list with size x to store the data of price changes.\n",
    "    price_change=list(range(x))\n",
    "    # Create empty lists of surge and crash data, surge and crash dates because of their unknown size\n",
    "    surge_data=[]\n",
    "    crash_data=[]\n",
    "    dates_surge=[]\n",
    "    dates_crash=[]\n",
    "    # Implement for loop x times to calculate the price changes, split into two cases of surge and crash.\n",
    "    for i in range(0,x):\n",
    "        # price change=close_data-open_data\n",
    "        price_change[i]=close_data[i]-open_data[i]\n",
    "        # Implement conditional statements to split price changes and dates into two cases of surge and crash.\n",
    "        if price_change[i]>0: # If price change is positive, append it to the surge data list \n",
    "                              # and the corresponding dates is appended to surge dates list            \n",
    "            surge_data.append(price_change[i])\n",
    "            dates_surge.append(date_data[i])\n",
    "        else:  # If price change is negative, append it to the crash data list \n",
    "               # and the corresponding dates is appended to crash dates list\n",
    "            crash_data.append(price_change[i])\n",
    "            dates_crash.append(date_data[i])\n",
    "    # Sorting the indices of surge and crash lists that their values are from low to high\n",
    "    sort_indices_surge=np.argsort(surge_data)\n",
    "    sort_indices_crash=np.argsort(np.abs(crash_data)) # Take absolute values because the crash data is negative\n",
    "    # Find the length of surge and crash lists\n",
    "    y=len(surge_data)\n",
    "    # Create original surge and crash lists with the size y to implement for loop \n",
    "    surge_data_sorted=list(range(y))\n",
    "    crash_data_sorted=list(range(y))\n",
    "    dates_surge_sorted=list(range(y))\n",
    "    dates_crash_sorted=list(range(y))\n",
    "    # Implement for loop to sort the values of surge and crash lists from largest to smallest\n",
    "    for j in range(0,y):\n",
    "        # The indices are sorted from low to high following their values, so the largest data is taken from the last index.\n",
    "        surge_data_sorted[j]=surge_data[sort_indices_surge[y-1-j]]\n",
    "        dates_surge_sorted[j]= dates_surge[sort_indices_surge[y-1-j]]\n",
    "        crash_data_sorted[j]=np.abs(crash_data[sort_indices_crash[y-1-j]])\n",
    "        dates_crash_sorted[j]= dates_crash[sort_indices_surge[y-1-j]]\n",
    "    # Implement conditional statements for two cases of surge and crash,\n",
    "    # and limit the length of the output lists to  num_output_dates\n",
    "    if detect_type=='surge':\n",
    "        date_list=dates_surge_sorted[:num_output_dates]\n",
    "        price_change_list=surge_data_sorted[:num_output_dates]\n",
    "    else: # detect_type=='crash'\n",
    "        date_list=dates_crash_sorted[:num_output_dates]\n",
    "        price_change_list=crash_data_sorted[:num_output_dates]\n",
    "    \n",
    "    return date_list, price_change_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d8ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list_t, price_change_list_t = detect_surge_crash(filepath = path to TSLA.csv, detect_type = 'surge', num_output_dates = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date_list_t, price_change_list_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b62f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list_g, price_change_list_g = detect_surge_crash(filepath = path to GOOGL.csv, detect_type = 'crash', num_output_dates = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdf3f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date_list_g, price_change_list_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc480d9",
   "metadata": {},
   "source": [
    "## Extra credit: Code efficiency\n",
    "### Achieve a runtime speed of < 10ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94179472",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit -n 1 -r 7 date_list_t, price_change_list_t = detect_surge_crash(filepath = path to TSLA.csv, detect_type = 'surge', num_output_dates = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5605702f",
   "metadata": {},
   "source": [
    "### Exercise 5: Human Debugger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5387df5",
   "metadata": {},
   "source": [
    "<img src=\"lab4_exercise5.png\" width=\"1200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61790f59",
   "metadata": {},
   "source": [
    "### Faulty function #1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d54fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_data_per_col(arr_2d):\n",
    "    \n",
    "    # NOTE FROM YOUR FRIEND PREPARING FOR STARBUCKS SOFTWARE ENGINEER TECH INTERVIEW \n",
    "    \"\"\"  The function takes numpy 2d array as an input, computes mean for each column data, and outputs 1D array \n",
    "         with the length equal to the # of columns.\n",
    "         \n",
    "         For some reason I keep getting errors.... I need your help to debug the code.\n",
    "         I need this position so I can get free ice lattes... :(\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # placeholder for averaged values\n",
    "    averaged_data = ()\n",
    "    \n",
    "    # Loop through each column data to compute mean and append to averaged_data \n",
    "    for k in range(len(arr_2d[:, 0])):\n",
    "        \n",
    "        averaged_column_data = np.mean(arr_2d[:, k])\n",
    "        averaged_data.append(averaged_column_data)\n",
    "        \n",
    "    # Return numpy array form of the averaged_data\n",
    "    return np.array(averaged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ddb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes.csv and convert to numpy array\n",
    "\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "diabetes_np = diabetes.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0769db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run faulty function 1\n",
    "\n",
    "averaged_diabetic_attributes =  average_data_per_col(diabetes_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR FIXED FUNCTION HERE\n",
    "# Make sure you comment on your fixes\n",
    "\n",
    "def average_data_per_col_fixed(arr_2d):\n",
    "    \n",
    "    # placeholder for averaged values\n",
    "    averaged_data = []  # {} -> []\n",
    "                        # It should be a list to append an element, 'tuple' object has no attribute 'append'\n",
    "    \n",
    "    # Loop through each column data to compute mean and append to averaged_data \n",
    "    for k in range(len(arr_2d[0, :])):\n",
    "        # len(arr_2d[:, 0]) -> len(arr_2d[0, :])\n",
    "        # k refers to the number of columns of arr_2d because we need find average value of each column,\n",
    "        # so we need to find the length of the first row in arr_2d, not the length of the first column.\n",
    "        averaged_column_data = np.mean(arr_2d[:, k])\n",
    "        averaged_data.append(averaged_column_data)\n",
    "        \n",
    "    # Return numpy array form of the averaged_data\n",
    "    return np.array(averaged_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1aad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your fixed function\n",
    "\n",
    "averaged_diabetic_attributes =  average_data_per_col_fixed(diabetes_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97927a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with correct results\n",
    "\n",
    "correct_result_func1 = np.load('E5_correct_output_1.npy')\n",
    "\n",
    "# Should return True if the result is correct\n",
    "np.sum(np.round(correct_result_func1, 3) == np.round(averaged_diabetic_attributes, 3)) == len(correct_result_func1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283bc04d",
   "metadata": {},
   "source": [
    "### Faulty function #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_stock_change_2_normalized_percentage(opening_price_arr, closing_price_arr):\n",
    "    \n",
    "    # NOTE FROM YOUR FRIEND WHO INVESTED IN TESLA\n",
    "    \"\"\"  I want to write a function which takes 2 1D numpy arrays of each corresponding to opening/closing prices of stock\n",
    "         and output 1D array of daily stock change in percentages. \n",
    "         \n",
    "         I want the percentages scale to be in a scale such that 1 = 100%, -0.5 = -50%, 1.5 = 150%  etc.\n",
    "         For example, day 1 opening: $10, day 1 closing: $15, change in scaled percecntage: 0.5.\n",
    "         \n",
    "         I am not really getting errors but the numbers don't look right... Can you help me?? :'( \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # placeholder for change percentage values\n",
    "    change_percentages = np.zeros(len(opening_price_arr), dtype = 'int')\n",
    "    \n",
    "    # Loop through each opening/closing price to compute the change percentage\n",
    "    for date_num in range(len(opening_price_arr)):\n",
    "        \n",
    "        change_percentages[date_num] = opening_price_arr[date_num] - closing_price_arr[date_num] / opening_price_arr[date_num]\n",
    "    \n",
    "    return change_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6008e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tsla.csv and convert to numpy array\n",
    "\n",
    "tesla = pd.read_csv('TSLA.csv') \n",
    "tesla_np = tesla.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run faulty function 2\n",
    "\n",
    "change_percentages = daily_stock_change_2_normalized_percentage(tesla_np[:, 1], tesla_np[:, 4])\n",
    "print(change_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a52a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR FIXED FUNCTION HERE\n",
    "# Make sure you comment on your fixes\n",
    "\n",
    "def daily_stock_change_2_normalized_percentage_fixed(opening_price_arr, closing_price_arr):\n",
    "    \n",
    "    # placeholder for change percentage values\n",
    "    # Because the percentages scale is not integer, we should not set dtype='int' for the value of change_percentages array.\n",
    "    change_percentages = np.zeros(len(opening_price_arr))\n",
    "    \n",
    "    # Loop through each opening/closing price to compute the change percentage\n",
    "    for date_num in range(len(opening_price_arr)):\n",
    "        # Because division takes precedence over subtraction, we should enclose the subtraction in parentheses.\n",
    "        change_percentages[date_num] = (closing_price_arr[date_num]-opening_price_arr[date_num]) / opening_price_arr[date_num]\n",
    "    \n",
    "    return change_percentages\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a62383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your fixed function\n",
    "\n",
    "change_percentages = daily_stock_change_2_normalized_percentage_fixed(tesla_np[:, 1], tesla_np[:, 4])\n",
    "print(change_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with correct results\n",
    "\n",
    "correct_result_func2 = np.load('E5_correct_output_2.npy')\n",
    "\n",
    "# Should return True if the result is correct\n",
    "np.sum(np.round(correct_result_func2, 3) == np.round(change_percentages, 3)) == len(correct_result_func2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f376cc",
   "metadata": {},
   "source": [
    "### Faulty function #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f49798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_diabetes_by_age(diabetes_data):\n",
    "    \n",
    "    # NOTE FROM YOUR FRIEND WHO WORKS AT UW IHME\n",
    "    \"\"\" The function takes diabetes pandas data frame as an input and outputs a subplot of 3 x 1 with three histograms.    \n",
    "    \n",
    "        Specifically, I want to divide the diabetes data into three age groups - \n",
    "            1. 20 to 40\n",
    "            2. 40 to 60\n",
    "            3. 60 to 80\n",
    "            \n",
    "        and plot 3 histograms of glucose distribution (50 bins per histogram) in 3 x 1 python subplots.\n",
    "        \n",
    "        I seem to be getting error from very beginning even before I divide the dataset....\n",
    "        My coworkers at IHME prefer R rather than Python... so you are my only hope!  \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the age column of the diabetes_data \n",
    "    age_column = diabetes_data[:, 8] \n",
    "    \n",
    "    # Construct boolean mask for each age group \n",
    "    age_20_40_bool_mask = age_column > 20 + age_column < 40\n",
    "    age_40_60_bool_mask = age_column > 40 + age_column < 60\n",
    "    age_60_80_bool_mask = age_column > 60 + age_column < 80\n",
    "    \n",
    "    # Get glucose data for each age group via applying the boolean mask for each age group\n",
    "    age_20_40_glucose = diabetes_data[age_20_40_bool_mask, 2]\n",
    "    age_40_60_glucose = diabetes_data[age_40_60_bool_mask, 2]\n",
    "    age_60_80_glucose = diabetes_data[age_60_80_bool_mask, 2]\n",
    "    \n",
    "    # Plot the histogram for each age group in 3 x 1 subplot\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    \n",
    "    plt.subplot(3,1,1)\n",
    "    \n",
    "    plt.hist(age_20_40_glucose, bins = 50)\n",
    "    plt.title('Age 20 to 40', fontsize = 15)\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    \n",
    "    plt.hist(age_40_60_glucose, bins = 50)\n",
    "    plt.title('Age 40 to 60', fontsize = 15)\n",
    "    \n",
    "    plt.subplot(3,1,3)\n",
    "    \n",
    "    plt.hist(age_60_80_glucose, bins = 50)\n",
    "    plt.title('Age 60 to 80', fontsize = 15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6356d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diabetes.csv as pandas dataframe\n",
    "\n",
    "diabetes = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run faulty function 3\n",
    "\n",
    "subset_diabetes_by_age(diabetes_data = diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31505293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR FIXED FUNCTION HERE\n",
    "# Make sure you comment on your fixes\n",
    "\n",
    "def subset_diabetes_by_age_fixed(diabetes_data):\n",
    "    # Because the parameter diabetes_data is given in csv file, we firstly should convert it to Numpy array \n",
    "    diabetes_np = diabetes_data.to_numpy()\n",
    "    # Extract the age column of the diabetes_data \n",
    "    age_column = diabetes_np[:, 7] # The column represents for the age should be 7 , not 8\n",
    "    \n",
    "    # Construct boolean mask for each age group \n",
    "    # The '+' operation gives True for all the boolean outputs, it should be change into '&'\n",
    "    # Comparison operation should be enclosed by parentheses \n",
    "    # to eliminate the error \"the truth value of an array with more than one element is ambiguous\"\n",
    "    age_20_40_bool_mask= (age_column > 20) & (age_column < 40)\n",
    "    age_40_60_bool_mask= (age_column > 40) & (age_column < 60)\n",
    "    age_60_80_bool_mask= (age_column > 60) & (age_column < 80)\n",
    "    \n",
    "    # Get glucose data for each age group via applying the boolean mask for each age group\n",
    "    # The column represents for the glucose should be 1 , not 2\n",
    "    age_20_40_glucose = diabetes_np[age_20_40_bool_mask, 1]\n",
    "    age_40_60_glucose = diabetes_np[age_40_60_bool_mask, 1]\n",
    "    age_60_80_glucose = diabetes_np[age_60_80_bool_mask, 1]\n",
    "    \n",
    "    # Plot the histogram for each age group in 3 x 1 subplot\n",
    "    fig = plt.figure(figsize=(15,7))\n",
    "    \n",
    "    plt.subplot(3,1,1)\n",
    "    \n",
    "    plt.hist(age_20_40_glucose,color='blue', bins = 50)\n",
    "    plt.title('Age 20 to 40', fontsize = 15)\n",
    "    \n",
    "    plt.subplot(3,1,2)\n",
    "    \n",
    "    plt.hist(age_40_60_glucose,color='blue', bins = 50)\n",
    "    plt.title('Age 40 to 60', fontsize = 15)\n",
    "    \n",
    "    plt.subplot(3,1,3)\n",
    "    \n",
    "    plt.hist(age_60_80_glucose,color='blue', bins = 50)\n",
    "    plt.title('Age 60 to 80', fontsize = 15)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your fixed function\n",
    "# Compare your plot with the correct plot provided in template folder\n",
    "\n",
    "subset_diabetes_by_age_fixed(diabetes_data = diabetes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
